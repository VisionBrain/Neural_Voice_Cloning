# Neural_Voice_Cloning
1. Baidu Research **[Link](https://arxiv.org/pdf/1802.06006.pdf)**
2. Tested Speaker Audio **[Link](https://visionbrain.github.io/voicecloning.github.io/)** 

### Abstract :
* **Voice cloning is a highly desired feature for personalized speech interfaces. We introduce a neural voice cloning system that learns to synthesize a person’s voice from only a few audio samples. System that learns to synthesize a person’s voice from only a few audio samples. We study two approaches: speaker adaptation and speaker encoding.**
* **Speaker adaptation is based on fine-tuning a multi-speaker generative model. Speaker encoding is based on training a separate model to directly infer a new speaker embedding, which will be applied to a multi-speaker generative model. Speaker adaptation can achieve slightly better naturalness and similarity, cloning time and required memory for the speaker encoding approach are significantly less, making it more favorable for low-resource deployment.**

### Steps :
<p align="center">
    <img src="Img/Workflow.png" alt="Image" width="500" height="600"/>
</p>

### Audio :
Tested Speaker Audio **[Link](https://visionbrain.github.io/voicecloning.github.io/)** 
* But don't expect anything right.
* I won't make an official complaint.
* They make a selective perception process.

### Made By-
* **[VisionBrain](https://visionbrain.org) & Team**
* **Project Lead -[Aryan Karn](https://github.com/Aryan05)**
